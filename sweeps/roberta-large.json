
seeds = [47, 881]
hyperparameters = {
    "train/batch_size": 16,
    "train/accumulate_grad_batches": 1,
    "train/k-fold": 5,
    "train/max_epochs": 20,
    "val/val_check_interval": 10,
    "global/model": "smeoni/roberta-large-clrp",
    "global/tokenizer": "roberta-large",
    "global/reinit_pool_layer": False,
    "global/reinit_last_n_layer": 6,
    "global/tokenizer_config": {
        "return_tensors": "pt",
        "padding": True,
        "truncation": True,
        "max_length": 256,
    },
    "mixout": 0.4,
    "global/checkpoint": None,
    "optim/lr": 8e-5,
    "optim/cosine_lr": False,
    "optim/weight_decay": 0,
    "optim/layerwise_learning_rate_decay": 0.6,
}

sweep_config = {
    "method": "grid",
    "metric": {  # We want to maximize val_acc
        "name": "val/best_loss",
        "goal": "minimize",
    },
    "parameters": {
        "train_seed": {"values": seeds},
        "train_fold": {"values": [0, 1, 2, 3, 4]},
    },
}